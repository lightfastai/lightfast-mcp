# Lightfast MCP - Architecture Rearchitecture Proposal

## ðŸŽ¯ Executive Summary

This proposal outlines a comprehensive rearchitecture of the `src/tools/` package to address critical issues in performance, error handling, logging, naming conventions, and shared utilities.

## ðŸš¨ Current Issues

### Performance Problems
- **Connection Inefficiency**: Creating new MCP connections for each tool call
- **Sequential Startup**: Servers start one-by-one with arbitrary delays
- **Memory Leaks**: No proper connection pooling or resource management
- **Blocking Operations**: Mixed sync/async patterns causing bottlenecks

### Error Handling Problems
- **Generic Exceptions**: `except Exception as e:` everywhere loses context
- **No Recovery**: No retry mechanisms or graceful degradation
- **Silent Failures**: Many operations fail silently
- **Poor Error Propagation**: Errors don't bubble up with sufficient context

### Logging Problems
- **Inconsistent Levels**: Mixed debug/info/error usage
- **No Structure**: No correlation IDs or request tracing
- **Console Pollution**: Mixed logging and user output
- **No Metrics**: No performance or health metrics

### Naming Convention Problems
- **Inconsistent Patterns**: Mixed snake_case/camelCase
- **Unclear Hierarchies**: Confusing module vs class naming
- **Poor Discoverability**: Hard to find related functionality

### Shared Utilities Problems
- **Code Duplication**: Same patterns repeated across modules
- **No Common Types**: No shared error/result types
- **Scattered Config**: Configuration logic spread everywhere

## ðŸ—ï¸ Proposed Architecture

### 1. **New Package Structure**

```
src/tools/
â”œâ”€â”€ common/                     # ðŸ†• Shared utilities and types
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ types.py               # Common types and enums
â”‚   â”œâ”€â”€ errors.py              # Custom exception hierarchy
â”‚   â”œâ”€â”€ logging.py             # Structured logging utilities
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ async_utils.py         # Async utilities and patterns
â”‚   â””â”€â”€ metrics.py             # Performance and health metrics
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ manager.py             # ðŸ”„ Renamed from multi_server_manager.py
â”‚   â”œâ”€â”€ registry.py            # ðŸ”„ Renamed from server_registry.py
â”‚   â”œâ”€â”€ selector.py            # ðŸ”„ Renamed from server_selector.py
â”‚   â”œâ”€â”€ config_loader.py       # âœ… Keep but refactor
â”‚   â””â”€â”€ cli.py                 # âœ… Keep but refactor
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conversation_client.py # ðŸ”„ Renamed from multi_server_ai_client.py
â”‚   â”œâ”€â”€ conversation_session.py # ðŸ†• Extract conversation state management
â”‚   â”œâ”€â”€ tool_executor.py       # ðŸ†• Extract tool execution logic
â”‚   â”œâ”€â”€ providers/             # ðŸ†• AI provider abstractions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_provider.py
â”‚   â”‚   â”œâ”€â”€ claude_provider.py
â”‚   â”‚   â””â”€â”€ openai_provider.py
â”‚   â””â”€â”€ cli.py                 # âœ… Keep but refactor
â””â”€â”€ __init__.py
```

### 2. **Common Types and Error Handling**

#### `src/tools/common/types.py`
```python
from enum import Enum
from dataclasses import dataclass
from typing import Any, Optional, Union, TypeVar, Generic
from datetime import datetime

T = TypeVar('T')

class OperationStatus(Enum):
    """Standard operation status codes."""
    SUCCESS = "success"
    FAILED = "failed"
    PENDING = "pending"
    CANCELLED = "cancelled"
    TIMEOUT = "timeout"

class ServerState(Enum):
    """Server lifecycle states."""
    STOPPED = "stopped"
    STARTING = "starting"
    RUNNING = "running"
    STOPPING = "stopping"
    ERROR = "error"

@dataclass
class Result(Generic[T]):
    """Standard result type for all operations."""
    status: OperationStatus
    data: Optional[T] = None
    error: Optional[str] = None
    error_code: Optional[str] = None
    timestamp: datetime = None
    duration_ms: Optional[float] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.utcnow()
    
    @property
    def is_success(self) -> bool:
        return self.status == OperationStatus.SUCCESS
    
    @property
    def is_failed(self) -> bool:
        return self.status == OperationStatus.FAILED

@dataclass
class ServerInfo:
    """Enhanced server information."""
    name: str
    server_type: str
    state: ServerState
    host: str
    port: int
    transport: str
    url: Optional[str] = None
    pid: Optional[int] = None
    start_time: Optional[datetime] = None
    last_health_check: Optional[datetime] = None
    error_count: int = 0
    tool_count: int = 0
```

#### `src/tools/common/errors.py`
```python
"""Custom exception hierarchy for better error handling."""

class LightfastMCPError(Exception):
    """Base exception for all Lightfast MCP errors."""
    
    def __init__(self, message: str, error_code: str = None, details: dict = None):
        super().__init__(message)
        self.error_code = error_code or self.__class__.__name__
        self.details = details or {}

class ConfigurationError(LightfastMCPError):
    """Configuration-related errors."""
    pass

class ServerError(LightfastMCPError):
    """Server operation errors."""
    pass

class ServerStartupError(ServerError):
    """Server failed to start."""
    pass

class ServerConnectionError(ServerError):
    """Server connection issues."""
    pass

class ToolExecutionError(LightfastMCPError):
    """Tool execution errors."""
    pass

class AIProviderError(LightfastMCPError):
    """AI provider communication errors."""
    pass

class ValidationError(LightfastMCPError):
    """Input validation errors."""
    pass
```

### 3. **Enhanced Logging System**

#### `src/tools/common/logging.py`
```python
"""Structured logging with correlation IDs and metrics."""

import logging
import uuid
from contextvars import ContextVar
from typing import Any, Dict, Optional
from datetime import datetime

# Context variables for request tracing
correlation_id: ContextVar[str] = ContextVar('correlation_id', default='')
operation_context: ContextVar[Dict[str, Any]] = ContextVar('operation_context', default={})

class StructuredLogger:
    """Enhanced logger with structured output and correlation IDs."""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(f"LightfastMCP.{name}")
        self._setup_formatter()
    
    def _setup_formatter(self):
        """Setup structured JSON formatter."""
        # Implementation details...
        pass
    
    def _log_with_context(self, level: int, message: str, **kwargs):
        """Log with correlation ID and context."""
        extra = {
            'correlation_id': correlation_id.get(),
            'context': operation_context.get(),
            'timestamp': datetime.utcnow().isoformat(),
            **kwargs
        }
        self.logger.log(level, message, extra=extra)
    
    def info(self, message: str, **kwargs):
        self._log_with_context(logging.INFO, message, **kwargs)
    
    def error(self, message: str, error: Exception = None, **kwargs):
        if error:
            kwargs['error_type'] = type(error).__name__
            kwargs['error_details'] = str(error)
        self._log_with_context(logging.ERROR, message, **kwargs)

def get_logger(name: str) -> StructuredLogger:
    """Get a structured logger instance."""
    return StructuredLogger(name)

def with_correlation_id(func):
    """Decorator to add correlation ID to operations."""
    async def wrapper(*args, **kwargs):
        if not correlation_id.get():
            correlation_id.set(str(uuid.uuid4()))
        return await func(*args, **kwargs)
    return wrapper
```

### 4. **Performance Optimizations**

#### Connection Pool Manager
```python
class ConnectionPoolManager:
    """Manages persistent connections to MCP servers."""
    
    def __init__(self, max_connections_per_server: int = 5):
        self._pools: Dict[str, asyncio.Queue] = {}
        self._max_connections = max_connections_per_server
        self._active_connections: Dict[str, int] = {}
    
    async def get_connection(self, server_name: str) -> Client:
        """Get a connection from the pool or create new one."""
        # Implementation with connection reuse
        pass
    
    async def return_connection(self, server_name: str, client: Client):
        """Return connection to pool."""
        # Implementation
        pass
```

#### Concurrent Server Startup
```python
async def start_servers_concurrently(
    self, 
    configs: List[ServerConfig],
    max_concurrent: int = 3
) -> Dict[str, Result[ServerInfo]]:
    """Start multiple servers concurrently with proper error handling."""
    
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def start_single_server(config: ServerConfig) -> Result[ServerInfo]:
        async with semaphore:
            try:
                # Proper startup with health checks
                return await self._start_server_with_health_check(config)
            except Exception as e:
                return Result(
                    status=OperationStatus.FAILED,
                    error=str(e),
                    error_code=type(e).__name__
                )
    
    tasks = [start_single_server(config) for config in configs]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return {configs[i].name: results[i] for i in range(len(configs))}
```

### 5. **Improved Error Handling Patterns**

#### Retry Mechanism
```python
from tenacity import retry, stop_after_attempt, wait_exponential

class RetryableOperation:
    """Base class for operations that can be retried."""
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10)
    )
    async def execute_with_retry(self, operation: Callable) -> Result[Any]:
        """Execute operation with exponential backoff retry."""
        try:
            result = await operation()
            return Result(status=OperationStatus.SUCCESS, data=result)
        except (ServerConnectionError, ToolExecutionError) as e:
            logger.warning(f"Retryable error: {e}")
            raise
        except Exception as e:
            logger.error(f"Non-retryable error: {e}")
            return Result(
                status=OperationStatus.FAILED,
                error=str(e),
                error_code=type(e).__name__
            )
```

### 6. **Naming Convention Standards**

#### Key Naming Decisions

**`ConversationClient` (was `MultiServerAIClient`)**
```python
class ConversationClient:
    """Manages AI conversations across multiple MCP servers."""
    
    async def chat(self, message: str) -> ConversationResult
    async def start_conversation(self) -> ConversationSession
    async def continue_conversation(self, session_id: str, message: str) -> ConversationResult
    async def execute_tools(self, tool_calls: List[ToolCall]) -> List[ToolResult]
    async def get_conversation_history(self, session_id: str) -> List[ConversationStep]
```

**Why "ConversationClient" is perfect:**
- **ðŸŽ¯ Highly Descriptive**: Immediately clear this handles conversations
- **ðŸ§  Domain-Specific**: Emphasizes the conversational AI nature  
- **ðŸ’¡ Intuitive**: Users instantly understand its purpose
- **ðŸ”® Extensible**: Leaves room for other AI clients (`AnalyticsClient`, `BatchClient`)
- **ðŸ¢ Professional**: Follows enterprise software naming patterns
- **ðŸ“š Self-Documenting**: The name explains the functionality

**`ServerOrchestrator` (was `MultiServerManager`)**
```python
class ServerOrchestrator:
    """Orchestrates lifecycle and coordination of multiple MCP servers."""
    
    async def start_servers(self, configs: List[ServerConfig]) -> Dict[str, Result[ServerInfo]]
    async def stop_servers(self, server_names: List[str]) -> Dict[str, Result[None]]
    async def health_check_all(self) -> Dict[str, HealthStatus]
    async def restart_server(self, server_name: str) -> Result[ServerInfo]
```

#### File Naming
- **Modules**: `snake_case.py` (e.g., `conversation_client.py`, `server_orchestrator.py`)
- **Classes**: `PascalCase` (e.g., `ConversationClient`, `ServerOrchestrator`)
- **Functions/Methods**: `snake_case` (e.g., `start_conversation`, `execute_tools`)
- **Constants**: `UPPER_SNAKE_CASE` (e.g., `MAX_RETRY_ATTEMPTS`, `DEFAULT_TIMEOUT`)

#### Class Naming Patterns
- **Orchestrators**: `*Orchestrator` (e.g., `ServerOrchestrator`)
- **Managers**: `*Manager` (e.g., `ConfigManager`, `ConnectionManager`)
- **Clients**: `*Client` (e.g., `ConversationClient`, `MCPClient`)
- **Providers**: `*Provider` (e.g., `ClaudeProvider`, `OpenAIProvider`)
- **Handlers**: `*Handler` (e.g., `ErrorHandler`, `ConfigHandler`)
- **Sessions**: `*Session` (e.g., `ConversationSession`)
- **Executors**: `*Executor` (e.g., `ToolExecutor`)

### 7. **Configuration Management**

#### Centralized Config System
```python
class ConfigManager:
    """Centralized configuration management with validation."""
    
    def __init__(self):
        self._config_cache: Dict[str, Any] = {}
        self._validators: Dict[str, Callable] = {}
    
    def load_config(self, config_path: str) -> Result[Dict[str, Any]]:
        """Load and validate configuration."""
        try:
            config = self._load_from_file(config_path)
            validation_result = self._validate_config(config)
            if not validation_result.is_success:
                return validation_result
            
            self._config_cache[config_path] = config
            return Result(status=OperationStatus.SUCCESS, data=config)
        
        except Exception as e:
            return Result(
                status=OperationStatus.FAILED,
                error=f"Failed to load config: {e}",
                error_code="CONFIG_LOAD_ERROR"
            )
```

## ðŸš€ Implementation Plan

### Phase 1: Foundation (Week 1)
1. Create `common/` package with shared types and utilities
2. Implement structured logging system
3. Create custom exception hierarchy

### Phase 2: Core Refactoring (Week 2)
1. Refactor `MultiServerManager` with new patterns
2. Implement connection pooling
3. Add retry mechanisms and better error handling

### Phase 3: AI Client Enhancement (Week 3)
1. Refactor AI client with provider abstraction
2. Implement concurrent tool execution
3. Add performance metrics

### Phase 4: Testing and Documentation (Week 4)
1. Comprehensive test coverage
2. Performance benchmarking
3. Documentation updates

## ðŸ“Š Expected Benefits

### Performance Improvements
- **50-80% faster** server startup through concurrency
- **Connection reuse** reduces latency by 60-70%
- **Memory usage** reduced by 30-40% through proper resource management

### Reliability Improvements
- **Automatic retry** for transient failures
- **Circuit breaker** patterns for failing services
- **Graceful degradation** when servers are unavailable

### Developer Experience
- **Clear error messages** with actionable information
- **Structured logging** for easier debugging
- **Consistent APIs** across all modules
- **Better type safety** with proper type hints

### Maintainability
- **Reduced code duplication** by 40-50%
- **Clearer separation of concerns**
- **Easier testing** with dependency injection
- **Better documentation** through self-documenting code

## ðŸ”§ Migration Strategy

### Backward Compatibility
- Keep existing public APIs during transition
- Add deprecation warnings for old patterns
- Provide migration guides for users

### Gradual Migration
- Implement new patterns alongside existing code
- Migrate module by module
- Extensive testing at each step

This rearchitecture will transform the codebase into a more robust, performant, and maintainable system while preserving the excellent functionality that already exists. 